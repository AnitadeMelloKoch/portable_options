import experiments.divdis_monte.monte_perfect_options
import portable.option.divdis.policy.policy_and_initiation
import portable.agent.model.ppo 

__main__.MontePerfectOptionsExperiment.experiment_name                = "monte_meta_perfect_options"
__main__.MontePerfectOptionsExperiment.use_gpu                        = True
__main__.MontePerfectOptionsExperiment.add_curiosity                  = False
__main__.MontePerfectOptionsExperiment.use_privileged_state           = False

__main__.make_monte_with_skills_env.sticky_actions                    = False
__main__.make_monte_with_skills_env.clip_rewards                      = False
__main__.make_monte_with_skills_env.single_life                       = False
__main__.make_monte_with_skills_env.episode_life                      = False

MaskablePPOAgent.learning_rate                                               = 2.5e-4
MaskablePPOAgent.state_shape                                                 = (4, 84, 84)
MaskablePPOAgent.num_actions                                                 = 27
MaskablePPOAgent.update_interval                                             = 2048
MaskablePPOAgent.minibatch_size                                              = 64
MaskablePPOAgent.entropy_coef                                                = 0.01