import portable.agent.model.linear_q
import experiments.core.divdis_meta_experiment
import portable.option.divdis.divdis_option
import portable.option.divdis.policy.policy_and_initiation
import portable.agent.model.maskable_ppo 
import portable.option.divdis.divdis_classifier

DivDisMetaExperiment.experiment_name                                = "meta_image_full_50_timeout_one_head"
DivDisMetaExperiment.num_options                                    = 5
DivDisMetaExperiment.option_head_num                                = 1
DivDisMetaExperiment.num_primitive_actions                          = 0
DivDisMetaExperiment.use_gpu                                        = True
DivDisMetaExperiment.gpu_list                                       = [0]
DivDisMetaExperiment.make_videos                                    = False
DivDisMetaExperiment.classifier_epochs                              = 200
DivDisMetaExperiment.option_timeout                                 = 50

MaskablePPOAgent.learning_rate                                      = 2.5e-4
MaskablePPOAgent.state_shape                                        = (3, 64, 64)
MaskablePPOAgent.num_actions                                        = 5
MaskablePPOAgent.update_interval                                    = 100
MaskablePPOAgent.entropy_coef                                       = 0.01

PolicyWithInitiation.warmup_steps                                   = 1024
PolicyWithInitiation.prioritized_replay_anneal_steps                = 500000
PolicyWithInitiation.buffer_length                                  = 100000
PolicyWithInitiation.update_interval                                = 4
PolicyWithInitiation.q_target_update_interval                       = 10
PolicyWithInitiation.learning_rate                                  = 2.5e-4
PolicyWithInitiation.final_epsilon                                  = 0.01
PolicyWithInitiation.final_exploration_frames                       = 8e3
PolicyWithInitiation.batch_size                                     = 32
PolicyWithInitiation.num_actions                                    = 7
PolicyWithInitiation.policy_infeature_size                          = 6272
PolicyWithInitiation.q_hidden_size                                  = 128
PolicyWithInitiation.gru_hidden_size                                = 512
PolicyWithInitiation.image_input                                    = True

DivDisClassifier.learning_rate                                      = 0.0002
DivDisClassifier.num_classes                                        = 2
DivDisClassifier.diversity_weight                                   = 0.0001
DivDisClassifier.l2_reg_weight                                      = 0.0005

DivDisOption.exp_type                                               = "minigrid"
DivDisOption.tabular_beta                                           = 0.0001








